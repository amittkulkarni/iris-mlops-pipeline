name: 'IRIS MLOps Pipeline CI/CD'

on:
  push:
    branches: [ dev, master ]
  pull_request:
    branches: [ master ]

permissions:
  contents: read
  actions: read
  checks: write
  pull-requests: write

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.9
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run pytest with coverage and XML reports
      run: |
        pytest tests/ -v \
          --junitxml=pytest-report.xml \
          --cov=src \
          --cov-report=xml \
          --cov-report=term-missing
      continue-on-error: true

    - name: Publish test results
      uses: dorny/test-reporter@v2
      if: always()
      with:
        name: 'Pytest Results'
        path: 'pytest-report.xml'
        reporter: 'java-junit'
        fail-on-error: false

    - name: Run sanity test and generate report
      if: always()
      run: |
        python -c "
        import sys
        sys.path.append('src')

        try:
            from data_loader import load_iris_dataset
            from preprocessing import preprocess_iris_data
            from model import IrisModel
            from evaluation import evaluate_model_performance

            print('🚀 Running IRIS Pipeline Sanity Test')

            # Load and preprocess data
            df = load_iris_dataset()
            processed_df, scaler = preprocess_iris_data(df)

            feature_cols = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']
            X = processed_df[feature_cols]
            y = processed_df['target']

            # Train model
            model = IrisModel()
            results = model.train(X, y)

            # Evaluate
            metrics = evaluate_model_performance(results['y_test'], results['y_pred'])

            print(f'✅ Model Training Successful')
            print(f'📊 Test Accuracy: {results[\"test_accuracy\"]:.3f}')
            print(f'📊 Overall Accuracy: {metrics[\"accuracy\"]:.3f}')
            print(f'📊 F1 Score: {metrics[\"f1_score\"]:.3f}')
            print(f'✅ All sanity tests passed!')

        except Exception as e:
            print(f'❌ Sanity test failed: {str(e)}')
            exit(1)
        "

    - name: Comment PR with test results
      if: github.event_name == 'pull_request' && always()
      uses: actions/github-script@v6
      with:
        script: |
          const comment = `## 🧪 IRIS MLOps Pipeline Test Results

          ### ✅ Test Status: COMPLETED

          **Pipeline Execution:**
          - 🧪 Unit tests executed
          - 📊 Test reports generated
          - 🔍 Sanity tests completed

          Check the detailed results in the Actions tab.`;

          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });
